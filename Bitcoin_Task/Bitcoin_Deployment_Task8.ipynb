{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bitcoin_Deployment_Task8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_OfzbHmP_TZ",
        "outputId": "deba4267-dbd4-4a6b-d7e4-2e05d2f41024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "%autosave 5\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(5000)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Autosaving every 5 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY-5R2AB3GE6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Q_tkIBNH87",
        "outputId": "96501597-1a81-4dfe-8093-356ab51e0da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVRY7J6nQkTq",
        "outputId": "136571ec-de6e-468c-fe9e-a25b130a2d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Deployement/Bitcoin_dep/bitcoin_cash_price.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Market Cap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Feb 20, 2018</td>\n",
              "      <td>1543.27</td>\n",
              "      <td>1569.03</td>\n",
              "      <td>1414.35</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820,947,000</td>\n",
              "      <td>26,199,800,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Feb 19, 2018</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1553.81</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578,906,000</td>\n",
              "      <td>25,179,700,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Feb 18, 2018</td>\n",
              "      <td>1552.10</td>\n",
              "      <td>1641.40</td>\n",
              "      <td>1428.49</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907,873,000</td>\n",
              "      <td>26,344,200,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feb 17, 2018</td>\n",
              "      <td>1548.48</td>\n",
              "      <td>1568.64</td>\n",
              "      <td>1517.14</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641,719,000</td>\n",
              "      <td>26,280,100,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Feb 16, 2018</td>\n",
              "      <td>1373.16</td>\n",
              "      <td>1558.66</td>\n",
              "      <td>1369.68</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961,010,000</td>\n",
              "      <td>23,302,000,000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date     Open     High  ...    Close       Volume      Market Cap\n",
              "0  Feb 20, 2018  1543.27  1569.03  ...  1418.73  820,947,000  26,199,800,000\n",
              "1  Feb 19, 2018  1483.34  1553.81  ...  1534.77  578,906,000  25,179,700,000\n",
              "2  Feb 18, 2018  1552.10  1641.40  ...  1487.46  907,873,000  26,344,200,000\n",
              "3  Feb 17, 2018  1548.48  1568.64  ...  1551.39  641,719,000  26,280,100,000\n",
              "4  Feb 16, 2018  1373.16  1558.66  ...  1552.20  961,010,000  23,302,000,000\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep22cPp5ljgj"
      },
      "source": [
        "df = df[df['Date'] >= '2017-01-01']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC0LjrMvVLqI",
        "outputId": "97e24e33-68ed-4130-90d3-1308aaf7827b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 213 entries, 0 to 212\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Date        213 non-null    object \n",
            " 1   Open        213 non-null    float64\n",
            " 2   High        213 non-null    float64\n",
            " 3   Low         213 non-null    float64\n",
            " 4   Close       213 non-null    float64\n",
            " 5   Volume      213 non-null    object \n",
            " 6   Market Cap  213 non-null    object \n",
            "dtypes: float64(4), object(3)\n",
            "memory usage: 13.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jYuZspKUj_C"
      },
      "source": [
        "import datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01Sm1lKSlsao",
        "outputId": "bd6f8cb6-1120-4039-da07-a2f77256233a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 213 entries, 0 to 212\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype         \n",
            "---  ------      --------------  -----         \n",
            " 0   Date        213 non-null    datetime64[ns]\n",
            " 1   Open        213 non-null    float64       \n",
            " 2   High        213 non-null    float64       \n",
            " 3   Low         213 non-null    float64       \n",
            " 4   Close       213 non-null    float64       \n",
            " 5   Volume      213 non-null    object        \n",
            " 6   Market Cap  213 non-null    object        \n",
            "dtypes: datetime64[ns](1), float64(4), object(2)\n",
            "memory usage: 13.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QUgZQmnVvAb",
        "outputId": "8944f115-00f0-4a4c-e334-5794a940734a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Market Cap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>1543.27</td>\n",
              "      <td>1569.03</td>\n",
              "      <td>1414.35</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820,947,000</td>\n",
              "      <td>26,199,800,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1553.81</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578,906,000</td>\n",
              "      <td>25,179,700,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-18</td>\n",
              "      <td>1552.10</td>\n",
              "      <td>1641.40</td>\n",
              "      <td>1428.49</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907,873,000</td>\n",
              "      <td>26,344,200,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-17</td>\n",
              "      <td>1548.48</td>\n",
              "      <td>1568.64</td>\n",
              "      <td>1517.14</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641,719,000</td>\n",
              "      <td>26,280,100,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>1373.16</td>\n",
              "      <td>1558.66</td>\n",
              "      <td>1369.68</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961,010,000</td>\n",
              "      <td>23,302,000,000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date     Open     High      Low    Close       Volume      Market Cap\n",
              "0 2018-02-20  1543.27  1569.03  1414.35  1418.73  820,947,000  26,199,800,000\n",
              "1 2018-02-19  1483.34  1553.81  1483.34  1534.77  578,906,000  25,179,700,000\n",
              "2 2018-02-18  1552.10  1641.40  1428.49  1487.46  907,873,000  26,344,200,000\n",
              "3 2018-02-17  1548.48  1568.64  1517.14  1551.39  641,719,000  26,280,100,000\n",
              "4 2018-02-16  1373.16  1558.66  1369.68  1552.20  961,010,000  23,302,000,000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0EVC0NVTz-B"
      },
      "source": [
        "df['Date']=df['Date'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvnMMqS_lxt0",
        "outputId": "9c01e6f1-10a4-495a-c55d-88a8a20dd429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 213 entries, 0 to 212\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Date        213 non-null    object \n",
            " 1   Open        213 non-null    float64\n",
            " 2   High        213 non-null    float64\n",
            " 3   Low         213 non-null    float64\n",
            " 4   Close       213 non-null    float64\n",
            " 5   Volume      213 non-null    object \n",
            " 6   Market Cap  213 non-null    object \n",
            "dtypes: float64(4), object(3)\n",
            "memory usage: 13.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3tOmHd-wIob"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp3ycc5BwOZf"
      },
      "source": [
        "import datetime\n",
        "def date_iso(Date_1):\n",
        " x = Date_1.split(\"-\")\n",
        "\n",
        " a =int(x[0])\n",
        " b =int(x[1])\n",
        " c =int(x[2])\n",
        " yr = datetime.date(a,b,c).isocalendar()[0]\n",
        " week = datetime.date(a,b,c).isocalendar()[1]\n",
        " total = str(yr)+\"-\" +str(week)\n",
        " return total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cQOWMSRwQaR"
      },
      "source": [
        "# creating a new column iso_week\n",
        "df['iso_week'] = df['Date'].apply(lambda x: date_iso(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FYT5C3lwXup",
        "outputId": "ca445110-0cd1-4aae-c0f4-b7f4f61bdcf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Market Cap</th>\n",
              "      <th>iso_week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>1543.27</td>\n",
              "      <td>1569.03</td>\n",
              "      <td>1414.35</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820,947,000</td>\n",
              "      <td>26,199,800,000</td>\n",
              "      <td>2018-8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1553.81</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578,906,000</td>\n",
              "      <td>25,179,700,000</td>\n",
              "      <td>2018-8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-18</td>\n",
              "      <td>1552.10</td>\n",
              "      <td>1641.40</td>\n",
              "      <td>1428.49</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907,873,000</td>\n",
              "      <td>26,344,200,000</td>\n",
              "      <td>2018-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-17</td>\n",
              "      <td>1548.48</td>\n",
              "      <td>1568.64</td>\n",
              "      <td>1517.14</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641,719,000</td>\n",
              "      <td>26,280,100,000</td>\n",
              "      <td>2018-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>1373.16</td>\n",
              "      <td>1558.66</td>\n",
              "      <td>1369.68</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961,010,000</td>\n",
              "      <td>23,302,000,000</td>\n",
              "      <td>2018-7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date     Open     High  ...       Volume      Market Cap iso_week\n",
              "0  2018-02-20  1543.27  1569.03  ...  820,947,000  26,199,800,000   2018-8\n",
              "1  2018-02-19  1483.34  1553.81  ...  578,906,000  25,179,700,000   2018-8\n",
              "2  2018-02-18  1552.10  1641.40  ...  907,873,000  26,344,200,000   2018-7\n",
              "3  2018-02-17  1548.48  1568.64  ...  641,719,000  26,280,100,000   2018-7\n",
              "4  2018-02-16  1373.16  1558.66  ...  961,010,000  23,302,000,000   2018-7\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtlYHlqwwl0a"
      },
      "source": [
        "# Removing the ',' from Volume and Market Cap\n",
        "df['Volume'] = df['Volume'].apply(lambda x: x.replace(',', ''))\n",
        "df['Market Cap'] = df['Market Cap'].apply(lambda x: x.replace(',', ''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4BRpFMzyYF8"
      },
      "source": [
        " df['Volume'] = df['Volume'].astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYV81f4CxZhM",
        "outputId": "05bc9f6e-7cfa-4a00-8ec6-aaa7ed6cc873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Market Cap</th>\n",
              "      <th>iso_week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>1543.27</td>\n",
              "      <td>1569.03</td>\n",
              "      <td>1414.35</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820947000.0</td>\n",
              "      <td>26199800000</td>\n",
              "      <td>2018-8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1553.81</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578906000.0</td>\n",
              "      <td>25179700000</td>\n",
              "      <td>2018-8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-18</td>\n",
              "      <td>1552.10</td>\n",
              "      <td>1641.40</td>\n",
              "      <td>1428.49</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907873000.0</td>\n",
              "      <td>26344200000</td>\n",
              "      <td>2018-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-17</td>\n",
              "      <td>1548.48</td>\n",
              "      <td>1568.64</td>\n",
              "      <td>1517.14</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641719000.0</td>\n",
              "      <td>26280100000</td>\n",
              "      <td>2018-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>1373.16</td>\n",
              "      <td>1558.66</td>\n",
              "      <td>1369.68</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961010000.0</td>\n",
              "      <td>23302000000</td>\n",
              "      <td>2018-7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date     Open     High  ...       Volume   Market Cap  iso_week\n",
              "0  2018-02-20  1543.27  1569.03  ...  820947000.0  26199800000    2018-8\n",
              "1  2018-02-19  1483.34  1553.81  ...  578906000.0  25179700000    2018-8\n",
              "2  2018-02-18  1552.10  1641.40  ...  907873000.0  26344200000    2018-7\n",
              "3  2018-02-17  1548.48  1568.64  ...  641719000.0  26280100000    2018-7\n",
              "4  2018-02-16  1373.16  1558.66  ...  961010000.0  23302000000    2018-7\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtV_2hpHxf0P",
        "outputId": "80539177-50a7-413e-b658-65956b99c27d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 213 entries, 0 to 212\n",
            "Data columns (total 8 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Date        213 non-null    object \n",
            " 1   Open        213 non-null    float64\n",
            " 2   High        213 non-null    float64\n",
            " 3   Low         213 non-null    float64\n",
            " 4   Close       213 non-null    float64\n",
            " 5   Volume      213 non-null    float64\n",
            " 6   Market Cap  213 non-null    object \n",
            " 7   iso_week    213 non-null    object \n",
            "dtypes: float64(5), object(3)\n",
            "memory usage: 15.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc0tjzdMy-kx"
      },
      "source": [
        "# df['Date'] = pd.to_datetime(df['Date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lanPo7FTzIpd",
        "outputId": "798693f0-ea85-4490-8378-2f641db0db1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "#  Keep only the `close` and `volume` variables\n",
        "model_data = df[['Date', 'iso_week', 'Close', 'Volume']]\n",
        "model_data.columns = ['date', 'iso_week', 'close', 'volume']\n",
        "model_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>iso_week</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>2018-8</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820947000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>2018-8</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578906000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-18</td>\n",
              "      <td>2018-7</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907873000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-17</td>\n",
              "      <td>2018-7</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641719000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>2018-7</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961010000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date iso_week    close       volume\n",
              "0  2018-02-20   2018-8  1418.73  820947000.0\n",
              "1  2018-02-19   2018-8  1534.77  578906000.0\n",
              "2  2018-02-18   2018-7  1487.46  907873000.0\n",
              "3  2018-02-17   2018-7  1551.39  641719000.0\n",
              "4  2018-02-16   2018-7  1552.20  961010000.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXcWc780zKsM",
        "outputId": "e0fc1209-1964-4ba9-ace4-87d551da78b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 213 entries, 0 to 212\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   date      213 non-null    object \n",
            " 1   iso_week  213 non-null    object \n",
            " 2   close     213 non-null    float64\n",
            " 3   volume    213 non-null    float64\n",
            "dtypes: float64(2), object(2)\n",
            "memory usage: 8.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTxonjL70Has",
        "outputId": "5c01ee25-0d20-45b2-f523-18eb0a0f3911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Market Cap</th>\n",
              "      <th>iso_week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>1543.27</td>\n",
              "      <td>1569.03</td>\n",
              "      <td>1414.35</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820947000.0</td>\n",
              "      <td>26199800000</td>\n",
              "      <td>2018-8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1553.81</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578906000.0</td>\n",
              "      <td>25179700000</td>\n",
              "      <td>2018-8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-18</td>\n",
              "      <td>1552.10</td>\n",
              "      <td>1641.40</td>\n",
              "      <td>1428.49</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907873000.0</td>\n",
              "      <td>26344200000</td>\n",
              "      <td>2018-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-17</td>\n",
              "      <td>1548.48</td>\n",
              "      <td>1568.64</td>\n",
              "      <td>1517.14</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641719000.0</td>\n",
              "      <td>26280100000</td>\n",
              "      <td>2018-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>1373.16</td>\n",
              "      <td>1558.66</td>\n",
              "      <td>1369.68</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961010000.0</td>\n",
              "      <td>23302000000</td>\n",
              "      <td>2018-7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date     Open     High  ...       Volume   Market Cap  iso_week\n",
              "0  2018-02-20  1543.27  1569.03  ...  820947000.0  26199800000    2018-8\n",
              "1  2018-02-19  1483.34  1553.81  ...  578906000.0  25179700000    2018-8\n",
              "2  2018-02-18  1552.10  1641.40  ...  907873000.0  26344200000    2018-7\n",
              "3  2018-02-17  1548.48  1568.64  ...  641719000.0  26280100000    2018-7\n",
              "4  2018-02-16  1373.16  1558.66  ...  961010000.0  23302000000    2018-7\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4nJUK-S0bXA",
        "outputId": "91ca7c9b-d341-47ba-d786-4fb2f4e836ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date          0\n",
              "Open          0\n",
              "High          0\n",
              "Low           0\n",
              "Close         0\n",
              "Volume        0\n",
              "Market Cap    0\n",
              "iso_week      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygH4gFEViTNO"
      },
      "source": [
        "\"\"\"\n",
        "Series of normalization functions useful\n",
        "for normalizing time-series data.\n",
        "\"\"\"\n",
        "\n",
        "def z_score(series):\n",
        "    \"\"\"\n",
        "    Computes the normalized value using the Z-score\n",
        "    technique. The Z-score is a technique used for\n",
        "    normalizing Gaussian distributions representing\n",
        "    each observation in relation to the distribution's\n",
        "    mean and standard deviation. For precise definitions,\n",
        "    see the Wikipedia article:\n",
        "    \n",
        "        https://en.wikipedia.org/wiki/Standard_score\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    serie: list\n",
        "        List with sequential values to use.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    result: list\n",
        "        List with the normalized results.\n",
        "    \"\"\"\n",
        "    result = (series - series.mean()) / series.std(ddof=0)\n",
        "    return result\n",
        "\n",
        "def point_relative_normalization(series, reverse=False, last_value=None):\n",
        "    \"\"\"\n",
        "    Computes the normalized value for the values of a\n",
        "    given series by using the first element of the serie as p_0\n",
        "    as a reference for each p_i.\n",
        "    \n",
        "    This technique comes from Siraj Raval's YouTube video\n",
        "    \"How to Predict Stock Prices Easily - Intro to Deep Learning #7\",\n",
        "    available at:\n",
        "    \n",
        "        https://www.youtube.com/watch?v=ftMq5ps503w\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    serie: list\n",
        "        List with sequential values to use.\n",
        "    \n",
        "    reverse: bool, default True\n",
        "        If the method should de-normalize data.\n",
        "    \n",
        "    last_value: int or float\n",
        "        Used to de-normalize a dataset. Needs to \n",
        "        be passed if `reverse` is True.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    result: list\n",
        "        List with the normalized results.\n",
        "    \"\"\"\n",
        "    if reverse:\n",
        "        result = last_value * (series + 1)\n",
        "    else:\n",
        "        result = (series / series[0]) - 1\n",
        "\n",
        "    return result\n",
        "\n",
        "def maximum_and_minimum_normalization(series, boundary=(0, 1)):\n",
        "    \"\"\"\n",
        "    Computes the normalized value for the values of a\n",
        "    given serie by using that series maximum and minimum\n",
        "    values.\n",
        "    \n",
        "    This technique is a direct implementation from \n",
        "    scikit-learn, available at:\n",
        "    \n",
        "        http://scikit-learn.org/stable/modules/generated/\\\n",
        "            sklearn.preprocessing.MinMaxScaler.html\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    serie: list\n",
        "        List with sequential values to use.\n",
        "    \n",
        "    boundary: set\n",
        "        Maximum and minimum values used to\n",
        "        scale the series.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    result: list\n",
        "        List with the normalized results.\n",
        "    \"\"\"\n",
        "    range_min, range_max = boundary\n",
        "    standard_deviation = (series - series.min(axis=0)) / (series.max(axis=0) - series.min(axis=0))\n",
        "    result = standard_deviation * (range_max - range_min) + range_min\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkAIXEbYl0zG"
      },
      "source": [
        "\"\"\"\n",
        "Helper class and methods for making manipulating\n",
        "data for models.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "#  from cryptonic.models import normalizations\n",
        "\n",
        "\n",
        "class ModelHelper:\n",
        "    \"\"\"\n",
        "    Class with utility functions that aid in \n",
        "    the process of training LSTM models with Keras.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def create_groups(self, data, start=0, group_size=7, normalize=True):\n",
        "        \"\"\"\n",
        "        Creates distinct groups from a given continuous series.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data: np.array\n",
        "            Series of continious observations.\n",
        "        \n",
        "        start: int\n",
        "            Starting point for the series. This \n",
        "            is used to prune earlier observations\n",
        "            from the series in case the series is\n",
        "            too long or too short.\n",
        "\n",
        "        group_size: int, default 7\n",
        "            Determines how large the groups are. That is,\n",
        "            how many observations each group contains.\n",
        "        \n",
        "        normalize: bool\n",
        "            If the method should normalize data or not.\n",
        "            Normalization is done using \n",
        "\n",
        "                normalizations.point_relative_normalization()\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        A Numpy array object. \n",
        "        \"\"\"\n",
        "        samples = list()\n",
        "        for i in range(0, len(data), group_size):\n",
        "            sample = list(data[start + i:i + group_size])\n",
        "            if len(sample) == group_size:\n",
        "                if normalize:\n",
        "                    sample = point_relative_normalization(sample)\n",
        "\n",
        "                samples.append(np.array(sample).reshape(1, group_size).tolist())\n",
        "\n",
        "        A = np.array(samples)\n",
        "        return A.reshape(1, A.shape[0], group_size)\n",
        "\n",
        "    def split_lstm_input(self, groups):\n",
        "        \"\"\"\n",
        "        Splits groups in a format expected by \n",
        "        the LSTM layer. \n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        groups: np.array\n",
        "            Numpy array with the organized sequences.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        X, Y: np.array\n",
        "            Numpy arrays with the shapes required by\n",
        "            the LSTM layer. X with (1, a - 1, b)\n",
        "            and Y with (1, b). Where a is the total\n",
        "            number of groups in `group` and b the\n",
        "            number of observations per group.\n",
        "        \"\"\"\n",
        "        X = groups[0:,:-1].reshape(1, groups.shape[1] - 1, groups.shape[2])\n",
        "        Y = groups[0:,-1:][0]\n",
        "\n",
        "        return X, Y\n",
        "\n",
        "    def normalize(self):\n",
        "        \"\"\"\n",
        "        Normalizes a series using point-relative normalization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        \"\"\"\n",
        "        point_relative_normalization()\n",
        "\n",
        "    def denormalize(self, series, last_value):\n",
        "        \"\"\"\n",
        "        De-normalizes a series using the latest\n",
        "        value available from data.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        series: numpy array\n",
        "            Series with normalized values.\n",
        "        \n",
        "        last_value: float\n",
        "            Numerical value that represents the\n",
        "            last value from the dataset.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        \"\"\"\n",
        "        result = last_value * (series + 1)\n",
        "        return result\n",
        "\n",
        "    def mape(self, A, B):\n",
        "        \"\"\"\n",
        "        Calcualtes the mean absolute persentage error\n",
        "        from two series. Original solution from:\n",
        "        \n",
        "            https://stats.stackexchange.com/questions/58391/\\\n",
        "                mean-absolute-percentage-error-mape-in-scikit-learn\n",
        "        \"\"\"\n",
        "        return np.mean(np.abs((A - B) / (1 - A))) * 100\n",
        "\n",
        "    def rmse(self, A, B):\n",
        "        \"\"\"\n",
        "        Calculates the root mean square error from\n",
        "        two series. Original solution from:\n",
        "\n",
        "            https://stackoverflow.com/questions/16774849\\\n",
        "                /mean-squared-error-in-numpy\n",
        "        \"\"\"\n",
        "        return np.sqrt(np.square(np.subtract(A, B)).mean())\n",
        "    \n",
        "    def mse(self, A, B):\n",
        "        \"\"\"\n",
        "        Calculates the mean square error from\n",
        "        two series. Original solution from:\n",
        "\n",
        "            https://stackoverflow.com/questions/16774849\\\n",
        "                /mean-squared-error-in-numpy\n",
        "        \"\"\"\n",
        "        return np.square(np.subtract(A, B)).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozDlg0KB0exk"
      },
      "source": [
        "\"\"\"\n",
        "Creates a deep learning model abstraction.\n",
        "\"\"\"\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.core import Dense, Activation\n",
        "\n",
        "#  from cryptonic.models.helper import ModelHelper\n",
        "#  from cryptonic.models.normalizations import point_relative_normalization\n",
        "\n",
        "\n",
        "class Model(ModelHelper):\n",
        "    \"\"\"\n",
        "    Class that encapsulates an LSTM model\n",
        "    that we have been building. This class makes it\n",
        "    easy to work with the different functions\n",
        "    used to work with the model.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    path: str\n",
        "        Location to load model from.\n",
        "\n",
        "    data: pandas DataFrame\n",
        "        Pandas dataframe with the variable from\n",
        "        `variable` privided. This is used\n",
        "        to eventually train and run the model.\n",
        "    \n",
        "    variable: str\n",
        "        Variable to use from `data`.\n",
        "    \n",
        "    predicted_period_size: int\n",
        "        Number of predicted time periods predictions\n",
        "        to make.\n",
        "    \n",
        "    holdout: int, default 0\n",
        "        Number of periods to hold-out from the \n",
        "        training set.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, data, variable, predicted_period_size, path=None, \n",
        "                 holdout=0, normalize=True):\n",
        "\n",
        "        self.path = path\n",
        "        self.data = data\n",
        "        self.variable = variable\n",
        "        self.predicted_period_size = predicted_period_size\n",
        "        self.holdout = holdout\n",
        "\n",
        "        if path:\n",
        "            self.model = load_model(self.path)\n",
        "\n",
        "        self.X, self.Y = self.__prepare_data(normalize=normalize)\n",
        "        self.__extract_last_series_value()\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "    def __extract_last_series_value(self):\n",
        "        \"\"\"\n",
        "        Method for extracting the last value from\n",
        "        a series prior to normalization. This value\n",
        "        is then used for denormalizing the set.\n",
        "        \"\"\"\n",
        "        if self.remainder:\n",
        "            self.last_value = self.data.sort_values('date', ascending=False)\\\n",
        "                                [:-self.remainder][self.variable].values[0]\n",
        "            \n",
        "            self.last_date = self.data.sort_values('date', ascending=False)\\\n",
        "                                [:-self.remainder]['date'].values[0]\n",
        "        else:\n",
        "            self.last_value = self.data.sort_values('date', ascending=False)\\\n",
        "                                [self.variable].values[0]\n",
        "            \n",
        "            self.last_date = self.data.sort_values('date', ascending=False)\\\n",
        "                                ['date'].values[0]\n",
        "    \n",
        "    def __prepare_data(self, normalize):\n",
        "        \"\"\"\n",
        "        Prepares data for model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        normalize: bool\n",
        "            If the method should normalize data or not.\n",
        "            Normalization is done using \n",
        "\n",
        "                normalizations.point_relative_normalization()\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        X and Y prepared for training.\n",
        "        \"\"\"\n",
        "        series = self.data[self.variable].values\n",
        "        self.remainder = len(series) % self.predicted_period_size\n",
        "\n",
        "        groups = self.create_groups(data=series, \n",
        "                                    group_size=self.predicted_period_size,\n",
        "                                    normalize=normalize)\n",
        "        \n",
        "        if self.holdout == 0:\n",
        "            self.holdout_groups = []\n",
        "        else:\n",
        "            self.holdout_groups = groups[::-self.holdout]\n",
        "            groups = groups[::-self.holdout]\n",
        "\n",
        "        self.default_number_of_periods = groups.shape[1] - 1\n",
        "\n",
        "        return self.split_lstm_input(groups)\n",
        "\n",
        "    def build(self, number_of_periods=None, period_length=7, batch_size=1):\n",
        "        \"\"\"\n",
        "        Builds an LSTM model using Keras. This function\n",
        "        works as a simple wrapper for a manually created\n",
        "        model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        period_length: int\n",
        "            The size of each observation used as input.\n",
        "        \n",
        "        number_of_periods: int, default None\n",
        "            The number of periods available in the \n",
        "            dataset. If None, the model will be built\n",
        "            using all available periods - 1 (used for validation).\n",
        "        \n",
        "        batch_size: int\n",
        "            The size of the batch used in each training\n",
        "            period.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        model: Keras model\n",
        "            Compiled Keras model that can be trained\n",
        "            and stored in disk.\n",
        "        \"\"\"\n",
        "        if not number_of_periods:\n",
        "            number_of_periods = self.default_number_of_periods\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(LSTM(\n",
        "            units=period_length,\n",
        "            batch_input_shape=(batch_size, number_of_periods, period_length),\n",
        "            input_shape=(number_of_periods, period_length),\n",
        "            return_sequences=False, stateful=False))\n",
        "\n",
        "        self.model.add(Dense(units=period_length))\n",
        "        self.model.add(Activation(\"linear\"))\n",
        "\n",
        "        self.model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"\n",
        "        Stores trained model in disk. Useful\n",
        "        for storing trained models.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        path: str\n",
        "            Location of where to store model.\n",
        "        \"\"\"\n",
        "        return self.model.save(path)\n",
        "    \n",
        "    def predict(self, denormalized=False, return_dict=False):\n",
        "        \"\"\"\n",
        "        Makes a prediction based on input data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        denormalized: bool, default True\n",
        "            If method should denormalize data. Method\n",
        "            will use the normalizations.point_relative_normalization()\n",
        "        \n",
        "        return_dict: bool, default False\n",
        "            If should return dict that can be serializable\n",
        "            as JSON. Useful for returning prediction\n",
        "            results with dates as keys.\n",
        "\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(x=self.X)\n",
        "        if denormalized:\n",
        "            predictions = point_relative_normalization(series=predictions, \n",
        "                                                       reverse=True, \n",
        "                                                       last_value=self.last_value)\n",
        "        \n",
        "        dates = []\n",
        "        base_date = datetime.strptime(self.last_date, '%Y-%m-%d')\n",
        "        for i in range(1, len(predictions[0] + 1)):\n",
        "            d = (base_date + timedelta(days=i)).strftime('%Y-%m-%d')\n",
        "            dates.append(d)\n",
        "\n",
        "        results = []\n",
        "        for d,p in zip(dates, predictions[0].tolist()):\n",
        "            results.append({\n",
        "                'date': d,\n",
        "                'prediction': round(p, 2)\n",
        "            })\n",
        "        \n",
        "        if return_dict:\n",
        "            return results\n",
        "        \n",
        "        else:\n",
        "            return predictions[0]\n",
        "\n",
        "    def train(self, data=None, epochs=300, verbose=0):\n",
        "        \"\"\"\n",
        "        Trains model using data from class. \n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: pandas DataFrame\n",
        "            Pandas dataframe with `variable` used to\n",
        "            fir model for the fist time.\n",
        "\n",
        "        epochs: int\n",
        "            Number of epochs to train model for.\n",
        "        \n",
        "        verbose: int, default 0\n",
        "            Verbosity level to use. The default (0)\n",
        "            means that nothing is printed on the\n",
        "            screen.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Metrics from the model history.\n",
        "        \"\"\"\n",
        "        if data is not None:\n",
        "            self.data = data\n",
        "            self.X, self.Y = self.__prepare_data(normalize=self.normalize)\n",
        "            self.__extract_last_series_value()\n",
        "\n",
        "        self.train_history = self.model.fit(\n",
        "            x=self.X, y=self.Y,\n",
        "            batch_size=1, epochs=epochs,\n",
        "            verbose=verbose, shuffle=False)\n",
        "\n",
        "        self.last_trained = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        return self.train_history\n",
        "\n",
        "    def evaluate(self, metrics=['mse', 'rmse', 'mape']):\n",
        "        \"\"\"\n",
        "        Evaluates model using provided metrics. The evaluation\n",
        "        \"\"\"\n",
        "        y = point_relative_normalization(series=self.Y[0], \n",
        "                                         reverse=True, \n",
        "                                         last_value=self.last_value)\n",
        "\n",
        "        results = {}\n",
        "        for metric in metrics:\n",
        "            if metric == 'mse':\n",
        "                r = round(\n",
        "                        self.mse(A=self.Y[0], B=self.predict()), 2)\n",
        "\n",
        "            else:\n",
        "                r = round(\n",
        "                        getattr(self, metric)(\n",
        "                        A=self.predict(denormalized=True)[0], \n",
        "                        B=y), 2)\n",
        "\n",
        "            results[metric] = r\n",
        "\n",
        "        return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-24id_SZ1kVi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZzSPam20lJR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcG3PVKl-EYY"
      },
      "source": [
        "## The `Model()` Class\n",
        "We have also created the class `Model()` which compiles all the code we have written so far. We will use that class to build, train, and evaluate our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYkmVEShb2vn",
        "outputId": "5d94c751-b4bd-4ecf-b951-ebb4ac39c010",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 213 entries, 0 to 212\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   date      213 non-null    object \n",
            " 1   iso_week  213 non-null    object \n",
            " 2   close     213 non-null    float64\n",
            " 3   volume    213 non-null    float64\n",
            "dtypes: float64(2), object(2)\n",
            "memory usage: 8.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKxm3TLt5kC8"
      },
      "source": [
        "M = Model(data=model_data,\n",
        "          variable='close',\n",
        "          predicted_period_size=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6mwzYF6cHBM",
        "outputId": "ff2dcc9e-ddcb-4a9e-cb20-34bf1324625b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "model_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>iso_week</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>2018-8</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820947000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>2018-8</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578906000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-18</td>\n",
              "      <td>2018-7</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907873000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-17</td>\n",
              "      <td>2018-7</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641719000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>2018-7</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961010000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date iso_week    close       volume\n",
              "0  2018-02-20   2018-8  1418.73  820947000.0\n",
              "1  2018-02-19   2018-8  1534.77  578906000.0\n",
              "2  2018-02-18   2018-7  1487.46  907873000.0\n",
              "3  2018-02-17   2018-7  1551.39  641719000.0\n",
              "4  2018-02-16   2018-7  1552.20  961010000.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7RyHSIkcn9A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvarV9GJ-GNM",
        "outputId": "bd4c2b24-9b5e-4622-db75-888758f579f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M.build()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f3d53dd2ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3RsPXp8-sG2",
        "outputId": "d1ea2802-233a-449a-c4e8-89013db7eb8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M.train(epochs=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0125\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 990us/step - loss: 0.0114\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 838us/step - loss: 0.0106\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0100\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0094\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 931us/step - loss: 0.0090\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 822us/step - loss: 0.0086\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0082\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 949us/step - loss: 0.0075\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 899us/step - loss: 0.0072\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 970us/step - loss: 0.0066\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0063\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 896us/step - loss: 0.0061\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 969us/step - loss: 0.0058\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 970us/step - loss: 0.0056\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0054\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0052\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0050\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0048\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0046\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0044\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0042\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0040\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 935us/step - loss: 0.0038\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0036\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0035\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0033\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0030\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0028\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0027\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0025\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 897us/step - loss: 0.0020\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 968us/step - loss: 0.0015\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 926us/step - loss: 0.0014\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 977us/step - loss: 9.8758e-04\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 953us/step - loss: 8.9656e-04\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 935us/step - loss: 8.1010e-04\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2825e-04\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5113e-04\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7881e-04\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1133e-04\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4875e-04\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9102e-04\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3818e-04\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9014e-04\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4686e-04\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.0818e-04\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 993us/step - loss: 1.7405e-04\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4408e-04\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 994us/step - loss: 1.1820e-04\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.5858e-05\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6984e-05\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1091e-05\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8034e-05\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7361e-05\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8935e-05\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2285e-05\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7324e-05\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3553e-05\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 991us/step - loss: 1.0966e-05\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0434e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.8864e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.9765e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.5409e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0968e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9749e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7414e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7735e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 880us/step - loss: 5.6709e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 965us/step - loss: 5.8141e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.8148e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 891us/step - loss: 6.0459e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 933us/step - loss: 6.1134e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3910e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4698e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7371e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7745e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9901e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9691e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1330e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 982us/step - loss: 7.0788e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2236e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1754e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3337e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3129e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.4936e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.4937e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6800e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3d1a1284e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsGQY27U-w2B"
      },
      "source": [
        "We can now use the model for making predictions with the `predict()` method. The parameter `denormalized` will return values in the original scale of the data. In our case, US dollars."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQw7uJ3V-tP4",
        "outputId": "c9de9d68-515c-44b1-ae4e-8740b01d8944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M.predict(denormalized=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1420.4897, 1095.1743, 1287.5242, 1434.7606, 1509.2275, 1442.2605,\n",
              "       1370.344 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bf9don-FxP6"
      },
      "source": [
        "We now evaluate our model to inspect the statistics for the last epoch of training compared to a single test week."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFaA6g97-yTI",
        "outputId": "f182e664-aa46-480f-d85e-aab9f7e39833",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mape': 6.42, 'mse': 0.0, 'rmse': 137.71}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lQqTqwfF2UB"
      },
      "source": [
        "Finally, we can now save the trained model on disk for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJtuWcN_F1S1"
      },
      "source": [
        "M.save('/content/drive/My Drive/Deployement/Bitcoin_dep/bitcoin_model_prod_v0.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvLyLqLyGsH9"
      },
      "source": [
        "Our `Model()` class can also load a previously trained model when instantiated with the `path` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp7Ml_I1Grfz"
      },
      "source": [
        "M = Model(path='/content/drive/My Drive/Deployement/Bitcoin_dep/bitcoin_model_prod_v0.h5',\n",
        "          data=model_data,\n",
        "          variable='close',\n",
        "          predicted_period_size=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JDPmruZFyxD",
        "outputId": "586c0b36-8654-45b4-a56d-1b26f178cd42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M.predict(denormalized=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1420.4897, 1095.1743, 1287.5242, 1434.7606, 1509.2275, 1442.2605,\n",
              "       1370.344 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0bWVFmzG_UU"
      },
      "source": [
        "## New Data, Re-train Old Model\n",
        "One strategy discussed earlier regards the re-training of our model with new data. In our case, our biggest concern is to shape data in a way that the model has been configured. As an example, we will configure our model to predict a week using 40 weeks. We will first train the model with the first 40 weeks of 2017, then continue to re-train it over the following weeks until we reach week 50."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIPk4uubHJRf"
      },
      "source": [
        "First, let's build a model with the first set of data. Notice how we use `7*40 + 7` as the indexer. This is because we use 40 weeks for training and 1 week for testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZVdOnKIG7Ki"
      },
      "source": [
        "M1 = Model(data=model_data[0*7:7*40 + 7],\n",
        "          variable='close',\n",
        "          predicted_period_size=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q43BLRM8HN6s",
        "outputId": "11280388-5432-4435-cbc6-4acc3a5d1d9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M1.build()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f3d53df70b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLnFk8ebHPT9",
        "outputId": "4b80dd66-65ed-429c-dd3a-23133470a807",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M1.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3d1645e630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVn97gE3HQmb"
      },
      "source": [
        "#\n",
        "#  Complete the range function and\n",
        "#  the model_data filtering parameters\n",
        "#  using an index to split the data in overlapping\n",
        "#  groups of 7 days. Then, re-train our model\n",
        "#  and collect the results.\n",
        "#\n",
        "#  The variables A, B, C, and D are placeholders.\n",
        "#\n",
        "#results = []\n",
        "#for i in range(0, 9 + 1):\n",
        "#    M1.train(model_data[i * 7:7 * (40 + i) + 7])\n",
        "#    results.append(M1.evaluate())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQez8kvmJ1NL"
      },
      "source": [
        "#  #  M1 = Model(data=model_data[i * 7:7 * (40 + i) + 7],variable='close',predicted_period_size=7)\n",
        "#  M1.build()\n",
        "#  M1.train()\n",
        "#  A = 1\n",
        "#  B = 10+1\n",
        "#  results = [] \n",
        "#  for i in range(A, B):\n",
        "#    M1.train(model_data[i * 7:7 * (40 + i) + 7])\n",
        "#    results.append(M1.evaluate())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLrFgI2aHe4p",
        "outputId": "0d582a4d-d924-40cd-db64-fcf929fddd97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "i=1\n",
        "M1 = Model(data=model_data[i * 7:7 * (40 + i) + 7],variable='close',predicted_period_size=7)\n",
        "M1.build()\n",
        "M1.train()\n",
        "results = [] \n",
        "for i in range(1, 10 + 1):\n",
        "    M1.train(epochs=100, verbose=1)\n",
        "    results.append(M1.evaluate())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8158e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7040e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9631e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 829us/step - loss: 5.4404e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 772us/step - loss: 4.0563e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 787us/step - loss: 2.8146e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 922us/step - loss: 2.1760e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7795e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6763e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7780e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 884us/step - loss: 2.3031e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 916us/step - loss: 3.5147e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 945us/step - loss: 5.2629e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8686e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5483e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 993us/step - loss: 3.0791e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0639e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5683e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4512e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6921e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 951us/step - loss: 2.5616e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 815us/step - loss: 4.4349e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7062e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.6005e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0419e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 824us/step - loss: 5.9492e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0312e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6044e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9686e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5917e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 982us/step - loss: 1.5109e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5394e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7429e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0042e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 877us/step - loss: 2.4601e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0006e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 936us/step - loss: 3.8956e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8337e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.1325e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6488e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4344e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7909e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5362e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4957e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9748e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6488e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5721e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6494e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0759e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1637e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2616e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5770e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3583e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5470e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 963us/step - loss: 2.2204e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5297e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2212e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 916us/step - loss: 1.1700e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 920us/step - loss: 1.4155e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 973us/step - loss: 2.1505e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 897us/step - loss: 4.0979e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5990e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 926us/step - loss: 1.0956e-05\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 941us/step - loss: 9.2035e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4750e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7431e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4977e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 867us/step - loss: 1.7487e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4608e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3382e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4108e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5652e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 956us/step - loss: 1.8759e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 932us/step - loss: 2.2582e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8870e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 979us/step - loss: 3.6180e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7320e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6773e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 960us/step - loss: 6.7657e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4573e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3987e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7043e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 902us/step - loss: 2.6842e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9553e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6194e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 944us/step - loss: 1.4376e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4689e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6799e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3569e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9387e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1917e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6666e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8401e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0163e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8477e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 987us/step - loss: 1.2640e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.8856e-07\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.0148e-07\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.6074e-07\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1882e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 934us/step - loss: 1.7716e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 889us/step - loss: 3.1892e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 864us/step - loss: 6.7415e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1285e-05\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2119e-05\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 933us/step - loss: 7.5973e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6908e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6716e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8338e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3549e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 915us/step - loss: 1.1845e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1295e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 962us/step - loss: 1.2283e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4104e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 895us/step - loss: 1.7527e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 870us/step - loss: 2.1738e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8077e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4891e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5335e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5744e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9379e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1176e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1588e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0164e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6978e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8185e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4126e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1936e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1890e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3527e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8919e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8108e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8657e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2404e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3141e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9141e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8152e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8605e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2505e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3495e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2525e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.4022e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7292e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6480e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1986e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0184e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1568e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7378e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1474e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8201e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6165e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3357e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6188e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4935e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.8631e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4923e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6475e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1309e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1730e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5478e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3710e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 965us/step - loss: 3.2805e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7982e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7742e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 902us/step - loss: 3.2379e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 905us/step - loss: 3.0417e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7612e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 843us/step - loss: 2.5391e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 924us/step - loss: 2.6823e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8172e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 841us/step - loss: 2.9368e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7637e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7429e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 904us/step - loss: 2.7620e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2922e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1146e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7025e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.7510e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 826us/step - loss: 7.5068e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0393e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1245e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4647e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6363e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2401e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2463e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6289e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4078e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2163e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8877e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.9881e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 979us/step - loss: 3.9515e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3709e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1379e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1632e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2491e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7270e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5458e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 855us/step - loss: 5.2332e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7709e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5498e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9794e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 983us/step - loss: 1.7219e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 848us/step - loss: 1.7631e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 876us/step - loss: 1.9392e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 808us/step - loss: 2.2735e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7205e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 817us/step - loss: 3.2637e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 950us/step - loss: 3.6335e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3655e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 815us/step - loss: 2.8061e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1305e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 841us/step - loss: 1.7544e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 914us/step - loss: 1.6227e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 908us/step - loss: 2.0954e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 888us/step - loss: 3.7342e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 900us/step - loss: 7.6765e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0583e-05\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.2072e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0254e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7609e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5230e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0228e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.0024e-07\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.8885e-07\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.1656e-07\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2218e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6188e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1924e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9316e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2511e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2763e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.6551e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5433e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8934e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.2481e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6834e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8331e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4193e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2193e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0911e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3808e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2088e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2573e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6378e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0666e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6661e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7860e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 988us/step - loss: 3.8558e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5075e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5383e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.3569e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2587e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8487e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6801e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5000e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5721e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5508e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6138e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4690e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3527e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1267e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0094e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8939e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8638e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8247e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8991e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2742e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2852e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0144e-05\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4039e-05\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.1835e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 779us/step - loss: 4.0299e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 909us/step - loss: 1.7905e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 864us/step - loss: 9.7970e-07\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 900us/step - loss: 6.2052e-07\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 916us/step - loss: 4.9750e-07\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8343e-07\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9173e-07\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7410e-07\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5315e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 958us/step - loss: 2.8048e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 819us/step - loss: 4.6840e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 989us/step - loss: 6.0320e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6096e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0332e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 839us/step - loss: 2.5601e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 895us/step - loss: 1.6939e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2379e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0779e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1983e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8238e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7105e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.3768e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0586e-05\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.5825e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 973us/step - loss: 5.8231e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2874e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 953us/step - loss: 2.1501e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4761e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 978us/step - loss: 1.2118e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1249e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2411e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4517e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7476e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0295e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4321e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8661e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5331e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 873us/step - loss: 4.2024e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2797e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0232e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5917e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2498e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7819e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4289e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7432e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3317e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2318e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3484e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9222e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0779e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7390e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3256e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9857e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8862e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5635e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1631e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6562e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0548e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8814e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0054e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6876e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7065e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2132e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9159e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8511e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2870e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0075e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0024e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5181e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2887e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 930us/step - loss: 1.3530e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 775us/step - loss: 1.7440e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 933us/step - loss: 2.8128e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 974us/step - loss: 4.6250e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2075e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5724e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 778us/step - loss: 4.2901e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7498e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0474e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7365e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 881us/step - loss: 2.0528e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 942us/step - loss: 2.9371e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 928us/step - loss: 4.5193e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4642e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 768us/step - loss: 5.2192e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9043e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 966us/step - loss: 2.9240e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2240e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 964us/step - loss: 1.9360e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8079e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8722e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0941e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6049e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3432e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 957us/step - loss: 3.6824e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 948us/step - loss: 3.4634e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7962e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5358e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 947us/step - loss: 2.7459e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 837us/step - loss: 4.0513e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9819e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 945us/step - loss: 7.4931e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 697us/step - loss: 6.2917e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5814e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.8161e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8834e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3159e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0808e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.9036e-07\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0780e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3203e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8829e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7622e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0170e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7119e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7111e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8718e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7299e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8119e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4815e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6524e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6162e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7969e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0939e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.4169e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0820e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8649e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8807e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0801e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6674e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 992us/step - loss: 3.2977e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6825e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4880e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.2232e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8937e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9617e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2001e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6136e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1730e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5130e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9917e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8919e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3568e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2548e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8780e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9010e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2222e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3960e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9251e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6570e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8092e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0993e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7685e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 987us/step - loss: 1.5683e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 898us/step - loss: 1.5802e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6911e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0294e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5757e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 949us/step - loss: 3.5275e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4819e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 938us/step - loss: 5.2173e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 839us/step - loss: 4.7939e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 855us/step - loss: 4.1943e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 927us/step - loss: 3.2397e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8548e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6971e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0340e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1573e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 884us/step - loss: 3.1370e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6540e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3952e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2431e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 996us/step - loss: 2.6413e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3291e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0242e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7572e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 994us/step - loss: 3.2174e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3772e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8427e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.5216e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4048e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3442e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3327e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3674e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5733e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2100e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6135e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0188e-05\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2258e-05\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8712e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5269e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6962e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0189e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2881e-07\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.7876e-07\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7934e-07\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0957e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7047e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7192e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9498e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7062e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.3548e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2186e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2518e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5983e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2733e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1791e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3454e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9915e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5810e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.6059e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 971us/step - loss: 8.7610e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.4144e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3969e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 842us/step - loss: 3.6179e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 960us/step - loss: 2.4092e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.9014e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5544e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 971us/step - loss: 1.4023e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3178e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3682e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4855e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7641e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 863us/step - loss: 2.1371e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 952us/step - loss: 2.7163e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2580e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8850e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2317e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.7822e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.1138e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3797e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2340e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2079e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2792e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9141e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8602e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3359e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1399e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2092e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4069e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8903e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8192e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1963e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8357e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9160e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3060e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2412e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2129e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0197e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6249e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1389e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2569e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7252e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1719e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8705e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6424e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6442e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8852e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6136e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 993us/step - loss: 3.5545e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3225e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4720e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7797e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9048e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1325e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8901e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0968e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1571e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9538e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8413e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2830e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8130e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0136e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0274e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3983e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1230e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.9240e-07\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0242e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1632e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5048e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0660e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0648e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2725e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6404e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1586e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 802us/step - loss: 5.4752e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6914e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8394e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4315e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6104e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8157e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9960e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8006e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8319e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 882us/step - loss: 2.8404e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9676e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7374e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5719e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2984e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2378e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1975e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4240e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8465e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9558e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4382e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5776e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5674e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2618e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8255e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0547e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5473e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 936us/step - loss: 1.3599e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3228e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5010e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 988us/step - loss: 1.8609e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 983us/step - loss: 2.5105e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 971us/step - loss: 3.3369e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 896us/step - loss: 4.0228e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 957us/step - loss: 4.1239e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 939us/step - loss: 3.4943e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6886e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9620e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5884e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 892us/step - loss: 1.4795e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8562e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 984us/step - loss: 2.9931e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 956us/step - loss: 5.5415e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 661us/step - loss: 7.8428e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 836us/step - loss: 7.7834e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9358e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.9983e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.7279e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1608e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.6230e-07\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6668e-07\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.7384e-07\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.2251e-07\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2259e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8471e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8059e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1189e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9929e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3073e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1324e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3060e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7160e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9104e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3265e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0249e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.0679e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7235e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0367e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5969e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1062e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7348e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4659e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5039e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9721e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1039e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.0504e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2979e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6350e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1599e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8327e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9959e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1894e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8683e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1803e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3760e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.0924e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8955e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1339e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5384e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0366e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.8137e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7069e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8719e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2414e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0345e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8740e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6919e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.5768e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.2713e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4827e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.9365e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3610e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0729e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.9187e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.0453e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3060e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.7436e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.0457e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3282e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.1470e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8776e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3334e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0763e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0497e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8217e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2130e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1613e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5710e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.1362e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5175e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2785e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9685e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0387e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9761e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8202e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3515e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9577e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6364e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.5638e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7167e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2427e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9410e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6185e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8451e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8971e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9607e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6880e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0917e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 880us/step - loss: 2.4000e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1699e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3290e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.2203e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4654e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.6134e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0789e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1116e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8669e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2187e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7971e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6823e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6403e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7062e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7480e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8109e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7741e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7801e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9011e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.5337e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8923e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.0357e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9313e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1978e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0349e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 918us/step - loss: 3.0633e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5159e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 847us/step - loss: 2.2375e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 905us/step - loss: 1.8739e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 869us/step - loss: 1.6940e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5757e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6416e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7462e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0146e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2893e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 901us/step - loss: 2.8113e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 769us/step - loss: 3.4172e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5117e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2432e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4032e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3043e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4760e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 942us/step - loss: 2.7467e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 945us/step - loss: 2.4921e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2664e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1418e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9657e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9386e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9836e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1894e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4937e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1130e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8602e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0510e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5919e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8111e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1860e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7548e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6801e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9331e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8691e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4905e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.4370e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2582e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9964e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1946e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1965e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5438e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2607e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1259e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1542e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2738e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5252e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8004e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.0321e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0497e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0485e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.1408e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6631e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5594e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7051e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6044e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5289e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3037e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6678e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4383e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1970e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.6673e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.9912e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3409e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9799e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2568e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.6559e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5250e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.7093e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 904us/step - loss: 1.8280e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7898e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5937e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5000e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 924us/step - loss: 1.5499e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 980us/step - loss: 1.9698e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 857us/step - loss: 2.8381e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 925us/step - loss: 4.4973e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9020e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 919us/step - loss: 6.2658e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 970us/step - loss: 4.7321e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 915us/step - loss: 3.5304e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5093e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0662e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7841e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6926e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6145e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6198e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6493e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8136e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0739e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4790e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9101e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4795e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.3066e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7763e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0185e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8116e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9769e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.5148e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 982us/step - loss: 1.4859e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9067e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 761us/step - loss: 3.2093e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2824e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0526e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9245e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2205e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5354e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7118e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2354e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0752e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0645e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2313e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5036e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8735e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1442e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2832e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2310e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3435e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7560e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 965us/step - loss: 3.9419e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3583e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3203e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3861e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 897us/step - loss: 4.9295e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2543e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 881us/step - loss: 3.4090e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3710e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7723e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3720e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2066e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1353e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2084e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3727e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7543e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 857us/step - loss: 2.3685e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 774us/step - loss: 3.5377e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 895us/step - loss: 4.9551e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1533e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3433e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.1771e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8752e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3145e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0208e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0258e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 949us/step - loss: 2.0185e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0185e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9071e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8534e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 987us/step - loss: 1.8656e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 968us/step - loss: 2.2183e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 915us/step - loss: 2.9841e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2070e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 932us/step - loss: 4.6313e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2417e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1143e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5959e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5080e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1072e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5442e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 840us/step - loss: 3.4106e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6951e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3052e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0202e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0262e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0455e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2780e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5318e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1836e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9300e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4704e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8444e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9238e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9662e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4127e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0834e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0030e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1817e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0796e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5322e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7878e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0307e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8115e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6812e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6978e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1528e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.4739e-07\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0029e-07\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0603e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5017e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5123e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8706e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6431e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1721e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5176e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5483e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9699e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6147e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8453e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7627e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1618e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4501e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1424e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4947e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2250e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8241e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7619e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7435e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9278e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7694e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4447e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9554e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.6366e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4191e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4187e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6078e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3274e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0380e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1759e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3873e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8410e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3319e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6200e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2570e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3179e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 878us/step - loss: 1.8535e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0700e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 902us/step - loss: 3.6621e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 847us/step - loss: 3.6186e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 980us/step - loss: 3.5829e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 937us/step - loss: 3.9831e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 872us/step - loss: 3.8350e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6117e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 884us/step - loss: 3.0496e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 973us/step - loss: 2.7613e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 938us/step - loss: 2.3738e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1026e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7913e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 966us/step - loss: 1.6307e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 907us/step - loss: 1.5878e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8588e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 877us/step - loss: 2.5987e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 881us/step - loss: 3.8088e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 876us/step - loss: 4.6059e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 904us/step - loss: 4.3459e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4479e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4147e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 870us/step - loss: 1.7959e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 972us/step - loss: 1.4661e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 913us/step - loss: 1.5265e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 972us/step - loss: 1.9553e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0878e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7190e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.1971e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4351e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0196e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4885e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6862e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1900e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.8652e-07\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0626e-07\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.7775e-07\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1647e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5678e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1515e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9313e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4760e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7747e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.4931e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3847e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4170e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0771e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4813e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4381e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0453e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0089e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4304e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3402e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5636e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2481e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1942e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8845e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0xBSU5wJxYh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HezXf6s7reZv",
        "outputId": "2f84f2c0-749c-48f7-8ac0-1d3e9cc064b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i, result in enumerate(results):\n",
        "    print(f'Week {40+i+1}: {result}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Week 41: {'mse': 0.0, 'rmse': 118.29, 'mape': 6.44}\n",
            "Week 42: {'mse': 0.0, 'rmse': 118.4, 'mape': 6.44}\n",
            "Week 43: {'mse': 0.0, 'rmse': 118.48, 'mape': 6.43}\n",
            "Week 44: {'mse': 0.0, 'rmse': 119.03, 'mape': 6.41}\n",
            "Week 45: {'mse': 0.0, 'rmse': 119.11, 'mape': 6.41}\n",
            "Week 46: {'mse': 0.0, 'rmse': 119.22, 'mape': 6.41}\n",
            "Week 47: {'mse': 0.0, 'rmse': 118.53, 'mape': 6.43}\n",
            "Week 48: {'mse': 0.0, 'rmse': 119.17, 'mape': 6.41}\n",
            "Week 49: {'mse': 0.0, 'rmse': 118.6, 'mape': 6.43}\n",
            "Week 50: {'mse': 0.0, 'rmse': 120.21, 'mape': 6.43}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA_FUdqerhfm",
        "outputId": "ec9a8c70-14fe-4540-830b-33f6f6ea3794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M1.predict(denormalized=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1235.0717,  951.2945, 1121.3511, 1250.872 , 1317.951 , 1251.9576,\n",
              "       1185.068 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI4orbYIrnGQ"
      },
      "source": [
        "old_data = model_data[0*7:7*48 + 7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGqFBxbxsTyv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGLPg-H7rpFP"
      },
      "source": [
        "new_data = model_data[0*7:7*49 + 7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOijjFEOruST"
      },
      "source": [
        "M2 = Model(data=old_data,\n",
        "          variable='close',\n",
        "          predicted_period_size=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELnOg5hZrxjX",
        "outputId": "5d700dbf-b1c2-4b5e-df3c-949d61034a10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M2.build()\n",
        "M2.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3d14230198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF8FqVGxr2On",
        "outputId": "491548ef-2f04-44e9-8bca-d21e3d796c80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M2.predict(denormalized=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1422.1395, 1100.9325, 1292.719 , 1440.1687, 1519.6587, 1440.946 ,\n",
              "       1368.1876], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxNgFCJDsVCB"
      },
      "source": [
        "M3 = Model(data=new_data,\n",
        "          variable='close',\n",
        "          predicted_period_size=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuOdQ6cDsVny",
        "outputId": "65aa70ca-7376-4b93-83cd-1e04f412408e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M3.build()\n",
        "M3.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3d12d38860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_lHNfDFsVtc",
        "outputId": "bcaa1457-4244-4a3d-866a-eb14d1a49bd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M3.predict(denormalized=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1422.7821, 1104.1722, 1287.8884, 1433.7885, 1514.5929, 1437.6469,\n",
              "       1362.2806], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRcFiDSusVzy",
        "outputId": "cf1989ce-5d21-4f88-beba-5c33c305bb2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M3.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mape': 6.43, 'mse': 0.0, 'rmse': 138.63}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbdRDsziDnH2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}